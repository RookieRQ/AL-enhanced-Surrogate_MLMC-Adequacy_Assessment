{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35435f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import MCCoordinator\n",
    "import StorageSampler\n",
    "\n",
    "def storage_system(**kwargs):\n",
    "    \"\"\"\n",
    "    Instantiate StorageSystem object using GB system data\n",
    "\n",
    "    :param wind_power: assumed wind power capacity (in MW)\n",
    "    :param kwargs: additional arguments to be supplied to the StorageSystem constructor\n",
    "    :return: StorageSystem object\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    data = pd.read_csv('../data/UKdata/20161213_uk_wind_solar_demand_temperature.csv',\n",
    "                       parse_dates=['UTC Time', 'Local Time'], infer_datetime_format=True, dayfirst=True, index_col=0)\n",
    "\n",
    "    demand_data = data['demand_net'].dropna()['2006':'2015']\n",
    "    wind_data = 10000 * data['wind_merra1'].dropna()\n",
    "\n",
    "    demand_samples = {yeardata[0]: yeardata[1].values[:8760] for yeardata in\n",
    "                      demand_data.groupby(demand_data.index.year)}\n",
    "    wind_samples = {yeardata[0]: yeardata[1].values[:8760] for yeardata in wind_data.groupby(wind_data.index.year)}\n",
    "\n",
    "    dataframe = pd.read_csv('../data/UKdata/battery_data.csv')\n",
    "    store_power_list=3*dataframe['Power (MW)'][0:27]\n",
    "    store_energy_list=3*dataframe['Energy (MWh)'][0:27]\n",
    "\n",
    "    return StorageSampler.StorageSystem(demand_samples=demand_samples, \n",
    "                                        wind_samples=wind_samples, \n",
    "                                        store_power_list=store_power_list,\n",
    "                                        store_energy_list=store_energy_list,\n",
    "                                        **kwargs)\n",
    "\n",
    "\n",
    "system = storage_system()\n",
    "\n",
    "import MachineLearning\n",
    "system.AI_model = MachineLearning.MachineLearning(train_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea44d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_generation(system, pool_size):\n",
    "    pool_temporal = np.zeros((pool_size, 24))\n",
    "\n",
    "    for i in range(pool_size):\n",
    "        pool_temporal[i] = system.generate_daily_margin_trace()\n",
    "    return pool_temporal\n",
    "\n",
    "def load_data(file_name):\n",
    "    '''\n",
    "    load data from the file_name\n",
    "    Parameters: \n",
    "        file_name: string\n",
    "            file address\n",
    "    Returns:\n",
    "        data: ndarray\n",
    "            an array of file's content\n",
    "    '''\n",
    "    data = np.ascontiguousarray(np.genfromtxt(file_name, delimiter=','))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "# Active learning strategy\n",
    "def random_forest_regression_std(regressor, X, n_instances=1):\n",
    "    all_tree_preds = np.array([tree.predict(X) for tree in regressor.estimator.estimators_])  # Shape: (n_trees, n_samples)\n",
    "\n",
    "    std = np.var(all_tree_preds, axis=0)\n",
    "    \n",
    "    query_idx = np.argsort(std)[-n_instances:]  # Last 10 indices after sorting\n",
    "    return query_idx, X[query_idx]\n",
    "\n",
    "def random_forest_regression_std_analysis(estimator, X, n_instances=1):\n",
    "    all_tree_preds = np.array([tree.predict(X) for tree in estimator.estimators_])  # Shape: (n_trees, n_samples)\n",
    "\n",
    "    std = np.var(all_tree_preds, axis=0)\n",
    "    \n",
    "    query_idx = np.argsort(std)[-n_instances:]  # Last 10 indices after sorting\n",
    "    return query_idx, X[query_idx], std[query_idx]\n",
    "\n",
    "# Random sampling strategy\n",
    "def random_sampling(regressor, X, n_instances=1):\n",
    "    query_idx = np.random.choice(X.shape[0], n_instances, replace=False)\n",
    "\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef38087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOL and ENS surrogate model for a year\n",
    "def surrogate_model_year_prediction(estimator, margin_year):\n",
    "    margin_daily = margin_year.reshape(-1, 365, 24)\n",
    "    return [np.sum(estimator.predict(margin_daily[i,:, :])) for i in range(margin_year.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e894a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogate_model_training(system, training_strategy, n_train_random=1825, n_initial=1825, n_queries=20, temporal_pool_size=3650, n_instances=91):\n",
    "    time_start = time.time()\n",
    "    if training_strategy == 'Random':\n",
    "        # Generate the training data\n",
    "        X_train = pool_generation(system, n_train_random)\n",
    "        y_train = np.array([system.run_optimal_policy(X_train[i]) for i in range(X_train.shape[0])])\n",
    "\n",
    "        lol_train = y_train[:,0]\n",
    "        ens_train = y_train[:,1]\n",
    "\n",
    "        lol_learner = RandomForestRegressor().fit(X_train, lol_train)\n",
    "        ens_learner = RandomForestRegressor().fit(X_train, ens_train)\n",
    "    \n",
    "    elif training_strategy == 'AL':    \n",
    "        X_train = pool_generation(system, n_initial)\n",
    "\n",
    "        y_train = np.array([system.run_optimal_policy(X_train[i]) for i in range(X_train.shape[0])])\n",
    "        lol_train = y_train[:,0]\n",
    "        ens_train = y_train[:,1]\n",
    "\n",
    "        # Initialize the learner\n",
    "        lol_learner = ActiveLearner(\n",
    "            estimator=RandomForestRegressor(),\n",
    "            query_strategy=random_forest_regression_std,\n",
    "            X_training=X_train, y_training=lol_train\n",
    "        )\n",
    "\n",
    "        ens_learner = ActiveLearner(\n",
    "            estimator=RandomForestRegressor(),\n",
    "            query_strategy=random_forest_regression_std,\n",
    "            X_training=X_train, y_training=ens_train\n",
    "        )\n",
    "\n",
    "        for i in range(n_queries):\n",
    "            X_pool_temporal = pool_generation(system, pool_size=temporal_pool_size)\n",
    "            \n",
    "            query_idx, query_inst = ens_learner.query(X_pool_temporal, n_instances=n_instances)\n",
    "\n",
    "            y_new = np.array([system.run_optimal_policy(query_inst[j]) for j in range(query_inst.shape[0])])\n",
    "            \n",
    "            lol_learner.teach(query_inst, y_new[:,0])\n",
    "            ens_learner.teach(query_inst, y_new[:,1])\n",
    "    else:\n",
    "        raise ValueError('Unknown training strategy: {}'.format(training_strategy))\n",
    "        \n",
    "    time_end = time.time()\n",
    "\n",
    "    return lol_learner, ens_learner, time_end - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib, verbose):\n",
    "    '''\n",
    "    Run MLMC simulation\n",
    "    Parameters:\n",
    "        samples: int\n",
    "            initial number of samples in each level for sigma estimation.\n",
    "        n_run: int\n",
    "            number of runs for MLMC simulation.\n",
    "        time_seconds: int\n",
    "            duration for each run of MLMC simulation.\n",
    "        ml_hierarchy: {'OptimalNStore', 'GreedyNStore', 'AIGreedyNStore', 'Greedy1Store', 'AvgStore', 'NoStore', 'AIModel'}\n",
    "            set of models for MLMC structure.\n",
    "        use_joblib: bool\n",
    "            if Ture: use all cores, otherwise run on a single core.\n",
    "        Verbose: bool\n",
    "            if Ture: print with details, otherwise: print summery of results\n",
    "    '''\n",
    "    mcc = MCCoordinator.MCCoordinator(factory=system, \n",
    "                                    ml_hierarchy=ml_hierarchy, \n",
    "                                    use_expectations=True, \n",
    "                                    use_joblib=use_joblib, joblib_n_jobs=-1, joblib_batch_size=5)\n",
    "    mcc.explore(n_samples=samples)\n",
    "    for i in range(n_run):\n",
    "        mcc.run_recommended(time_seconds=time_seconds, verbose=verbose, optimization_target='EENS')\n",
    "    mcc.verbose_result()\n",
    "    return mcc\n",
    "\n",
    "\n",
    "def round_to_n(x, n):\n",
    "    \"\"\"\n",
    "    Round x to n significant digits.\n",
    "\n",
    "    :param x: scalar to be converted\n",
    "    :param n: number of significant digits\n",
    "    :return: scalar\n",
    "    \"\"\"\n",
    "    import math\n",
    "\n",
    "    if np.isnan(x): return x\n",
    "    if np.sign(x) == 0: return 0.0\n",
    "    return np.round(x, -int(math.floor(math.log10(abs(x)))) + (n - 1))\n",
    "\n",
    "\n",
    "def generate_mcc_results(mcc):\n",
    "    \"\"\"\n",
    "    Print summary results to screen.\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Suppress divide by zeros and nan errors; store old settings to restore on return.\n",
    "    old_settings = np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "    # Compute the total time as computed by index computations and sample computations\n",
    "    total_time_level = sum([level_stats.sum for level_stats in mcc.level_exec_times.values()])\n",
    "    total_time = sum([set_stats.sum for set_stats in mcc.set_exec_times.values()])\n",
    "\n",
    "    # compute the overall MLMC estimate and its standard error, by quadratic summation of term errors\n",
    "    mean_result = sum([ml_stats.mean for key, ml_stats in mcc.ml_stats.items()])\n",
    "    stderr_result = np.sqrt(sum([ml_stats.stderr ** 2 for key, ml_stats in mcc.ml_stats.items()]))\n",
    "\n",
    "    est_time_per_target_sample = min([mcc.set_exec_times[level_set].mean for level_set in mcc.set_exec_times.keys() if mcc.target_level in level_set])\n",
    "    target_stats = mcc.level_stats[mcc.target_level]\n",
    "    est_time_spent_for_target_result = target_stats.count * est_time_per_target_sample\n",
    "\n",
    "    # report results, alongside an estimated 'computational speed'\n",
    "    results = [round_to_n(mcc.wall_clock_time, 3)]\n",
    "    for result_index, result_label in enumerate(mcc.output_labels):\n",
    "        results.append(round_to_n(mean_result[result_index], 4))\n",
    "        results.append(round_to_n(stderr_result[result_index], 2))\n",
    "        results.append(round_to_n(mean_result[result_index] ** 2 / (stderr_result[result_index] ** 2 * mcc.wall_clock_time), 3))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54edd57e",
   "metadata": {},
   "source": [
    "# Active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0eb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 10\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 20\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "training_strategy = 'AL' # 'AL' or 'Random'\n",
    "\n",
    "######################################################################################################\n",
    "# Hyperparameters for active learning\n",
    "n_initial = 365 * 2 # Initial training set, 2 years\n",
    "n_queries = 10 # 10 years\n",
    "temporal_pool_size = 3650 # 10 years\n",
    "n_instances = 91 # 1 season = 91 days\n",
    "\n",
    "#####################################################################################################\n",
    "# Hyperparameters for random sampling\n",
    "n_train_random = 365 * 5 + 365 * 5 * 18 # Initial training set, 5 years\n",
    "\n",
    "# Estimator: Surr , Architecture: Exact|Surrogate models\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "\n",
    "# [\"Training time\", \"Simulation time\", \"mean_LOL\", \"stderr_LOL\", \"speed_LOL\", \"mean_ENS\", \"stderr_ENS\", \"speed_ENS\"]\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "\n",
    "print('Training strategy: ', training_strategy)\n",
    "print('n_train_random: ', n_train_random)\n",
    "\n",
    "for i in range(n_run_MLMC):\n",
    "    lol_learner, ens_learner, results[i,0] = surrogate_model_training(system, training_strategy, n_train_random, n_initial, n_queries, temporal_pool_size, n_instances)\n",
    "    system.AI_model.lol_model = lol_learner\n",
    "    system.AI_model.ens_model = ens_learner\n",
    "\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "    # print('MLMC results: ', results[i,:])\n",
    "\n",
    "results_al = results.copy()\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 10\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 20\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "training_strategy = 'AL' # 'AL' or 'Random'\n",
    "\n",
    "######################################################################################################\n",
    "# Hyperparameters for active learning\n",
    "n_initial = 365 * 2 # Initial training set, 5 years\n",
    "n_queries = 20 # 10 years\n",
    "temporal_pool_size = 3650 # 10 years\n",
    "n_instances = 91 # 1 season = 91 days\n",
    "\n",
    "################################################################################################\n",
    "# Hyperparameters for random sampling\n",
    "n_train_random = 2735  # 365 * 5 + 365 * 5 * 5 # Initial training set, 5 years\n",
    "\n",
    "\n",
    "# Estimator: Surr , Architecture: Exact|Surrogate models\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "\n",
    "# [\"Training time\", \"Simulation time\", \"mean_LOL\", \"stderr_LOL\", \"speed_LOL\", \"mean_ENS\", \"stderr_ENS\", \"speed_ENS\"]\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "\n",
    "print('Training strategy: ', training_strategy)\n",
    "print('n_train_random: ', n_train_random)\n",
    "\n",
    "for i in range(n_run_MLMC):\n",
    "    lol_learner, ens_learner, results[i,0] = surrogate_model_training(system, training_strategy, n_train_random, n_initial, n_queries, temporal_pool_size, n_instances)\n",
    "    system.AI_model.lol_model = lol_learner\n",
    "    system.AI_model.ens_model = ens_learner\n",
    "\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "    # print('MLMC results: ', results[i,:])\n",
    "\n",
    "# results_random_11 = results.copy()\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b1b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 10\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 20\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "training_strategy = 'AL' # 'AL' or 'Random'\n",
    "\n",
    "######################################################################################################\n",
    "# Hyperparameters for active learning\n",
    "n_initial = 365 * 2 # Initial training set, 5 years\n",
    "n_queries = 30 # 10 years\n",
    "temporal_pool_size = 3650 # 10 years\n",
    "n_instances = 91 # 1 season = 91 days\n",
    "\n",
    "################################################################################################\n",
    "# Hyperparameters for random sampling\n",
    "n_train_random = 2735  # 365 * 5 + 365 * 5 * 5 # Initial training set, 5 years\n",
    "\n",
    "\n",
    "# Estimator: Surr , Architecture: Exact|Surrogate models\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "\n",
    "# [\"Training time\", \"Simulation time\", \"mean_LOL\", \"stderr_LOL\", \"speed_LOL\", \"mean_ENS\", \"stderr_ENS\", \"speed_ENS\"]\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "\n",
    "print('Training strategy: ', training_strategy)\n",
    "print('n_train_random: ', n_train_random)\n",
    "\n",
    "for i in range(n_run_MLMC):\n",
    "    lol_learner, ens_learner, results[i,0] = surrogate_model_training(system, training_strategy, n_train_random, n_initial, n_queries, temporal_pool_size, n_instances)\n",
    "    system.AI_model.lol_model = lol_learner\n",
    "    system.AI_model.ens_model = ens_learner\n",
    "\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "    # print('MLMC results: ', results[i,:])\n",
    "\n",
    "# results_random_11 = results.copy()\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6443fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 10\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 20\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "training_strategy = 'AL' # 'AL' or 'Random'\n",
    "\n",
    "######################################################################################################\n",
    "# Hyperparameters for active learning\n",
    "n_initial = 365 * 2 # Initial training set, 5 years\n",
    "n_queries = 5 # 10 years\n",
    "temporal_pool_size = 3650 # 10 years\n",
    "n_instances = 91 # 1 season = 91 days\n",
    "\n",
    "################################################################################################\n",
    "# Hyperparameters for random sampling\n",
    "n_train_random = 2735  # 365 * 5 + 365 * 5 * 5 # Initial training set, 5 years\n",
    "\n",
    "\n",
    "# Estimator: Surr , Architecture: Exact|Surrogate models\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "\n",
    "# [\"Training time\", \"Simulation time\", \"mean_LOL\", \"stderr_LOL\", \"speed_LOL\", \"mean_ENS\", \"stderr_ENS\", \"speed_ENS\"]\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "\n",
    "print('Training strategy: ', training_strategy)\n",
    "print('n_train_random: ', n_train_random)\n",
    "\n",
    "for i in range(n_run_MLMC):\n",
    "    lol_learner, ens_learner, results[i,0] = surrogate_model_training(system, training_strategy, n_train_random, n_initial, n_queries, temporal_pool_size, n_instances)\n",
    "    system.AI_model.lol_model = lol_learner\n",
    "    system.AI_model.ens_model = ens_learner\n",
    "\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "    # print('MLMC results: ', results[i,:])\n",
    "\n",
    "# results_random_11 = results.copy()\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c08df5f",
   "metadata": {},
   "source": [
    "# Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3832d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 5\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 20\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "training_strategy = 'Random' # 'AL' or 'Random'\n",
    "\n",
    "######################################################################################################\n",
    "# Hyperparameters for active learning\n",
    "n_initial = 365 * 2 # Initial training set, 5 years\n",
    "n_queries = 20 # 10 years\n",
    "temporal_pool_size = 3650 # 10 years\n",
    "n_instances = 91 # 1 season = 91 days\n",
    "\n",
    "################################################################################################\n",
    "# Hyperparameters for random sampling\n",
    "n_train_random = 365 * 5 + 365 * 5 * 3 # Initial training set, 5 years\n",
    "\n",
    "\n",
    "# Estimator: Surr , Architecture: Exact|Surrogate models\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "\n",
    "# [\"Training time\", \"Simulation time\", \"mean_LOL\", \"stderr_LOL\", \"speed_LOL\", \"mean_ENS\", \"stderr_ENS\", \"speed_ENS\"]\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "\n",
    "print('Training strategy: ', training_strategy)\n",
    "print('n_train_random: ', n_train_random)\n",
    "\n",
    "for i in range(n_run_MLMC):\n",
    "    lol_learner, ens_learner, results[i,0] = surrogate_model_training(system, training_strategy, n_train_random, n_initial, n_queries, temporal_pool_size, n_instances)\n",
    "    system.AI_model.lol_model = lol_learner\n",
    "    system.AI_model.ens_model = ens_learner\n",
    "\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "    # print('MLMC results: ', results[i,:])\n",
    "\n",
    "# results_random_11 = results.copy()\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ae895",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab32228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 10\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 20\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "training_strategy = 'Random' # 'AL' or 'Random'\n",
    "\n",
    "######################################################################################################\n",
    "# Hyperparameters for active learning\n",
    "n_initial = 365 * 2 # Initial training set, 5 years\n",
    "n_queries = 20 # 10 years\n",
    "temporal_pool_size = 3650 # 10 years\n",
    "n_instances = 91 # 1 season = 91 days\n",
    "\n",
    "################################################################################################\n",
    "# Hyperparameters for random sampling\n",
    "n_train_random = 365 * 5 + 365 * 5 * 7 # Initial training set, 5 years\n",
    "\n",
    "\n",
    "# Estimator: Surr , Architecture: Exact|Surrogate models\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "\n",
    "# [\"Training time\", \"Simulation time\", \"mean_LOL\", \"stderr_LOL\", \"speed_LOL\", \"mean_ENS\", \"stderr_ENS\", \"speed_ENS\"]\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "\n",
    "print('Training strategy: ', training_strategy)\n",
    "print('n_train_random: ', n_train_random)\n",
    "\n",
    "for i in range(n_run_MLMC):\n",
    "    lol_learner, ens_learner, results[i,0] = surrogate_model_training(system, training_strategy, n_train_random, n_initial, n_queries, temporal_pool_size, n_instances)\n",
    "    system.AI_model.lol_model = lol_learner\n",
    "    system.AI_model.ens_model = ens_learner\n",
    "\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "    # print('MLMC results: ', results[i,:])\n",
    "\n",
    "# results_random_11 = results.copy()\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 5\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 20\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "training_strategy = 'Random' # 'AL' or 'Random'\n",
    "\n",
    "######################################################################################################\n",
    "# Hyperparameters for active learning\n",
    "n_initial = 365 * 2 # Initial training set, 5 years\n",
    "n_queries = 20 # 10 years\n",
    "temporal_pool_size = 3650 # 10 years\n",
    "n_instances = 91 # 1 season = 91 days\n",
    "\n",
    "################################################################################################\n",
    "# Hyperparameters for random sampling\n",
    "n_train_random = 365 * 5 + 365 * 5 * 15 # Initial training set, 5 years\n",
    "\n",
    "\n",
    "# Estimator: Surr , Architecture: Exact|Surrogate models\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "\n",
    "# [\"Training time\", \"Simulation time\", \"mean_LOL\", \"stderr_LOL\", \"speed_LOL\", \"mean_ENS\", \"stderr_ENS\", \"speed_ENS\"]\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "\n",
    "print('Training strategy: ', training_strategy)\n",
    "print('n_train_random: ', n_train_random)\n",
    "\n",
    "for i in range(n_run_MLMC):\n",
    "    lol_learner, ens_learner, results[i,0] = surrogate_model_training(system, training_strategy, n_train_random, n_initial, n_queries, temporal_pool_size, n_instances)\n",
    "    system.AI_model.lol_model = lol_learner\n",
    "    system.AI_model.ens_model = ens_learner\n",
    "\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "    # print('MLMC results: ', results[i,:])\n",
    "\n",
    "# results_random_11 = results.copy()\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b70be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 5\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 20\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "training_strategy = 'Random' # 'AL' or 'Random'\n",
    "\n",
    "######################################################################################################\n",
    "# Hyperparameters for active learning\n",
    "n_initial = 365 * 2 # Initial training set, 5 years\n",
    "n_queries = 20 # 10 years\n",
    "temporal_pool_size = 3650 # 10 years\n",
    "n_instances = 91 # 1 season = 91 days\n",
    "\n",
    "################################################################################################\n",
    "# Hyperparameters for random sampling\n",
    "n_train_random = 365 * 5 + 365 * 4 * 1 # Initial training set, 5 years\n",
    "\n",
    "\n",
    "# Estimator: Surr , Architecture: Exact|Surrogate models\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "\n",
    "# [\"Training time\", \"Simulation time\", \"mean_LOL\", \"stderr_LOL\", \"speed_LOL\", \"mean_ENS\", \"stderr_ENS\", \"speed_ENS\"]\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "\n",
    "print('Training strategy: ', training_strategy)\n",
    "print('n_train_random: ', n_train_random)\n",
    "\n",
    "for i in range(n_run_MLMC):\n",
    "    lol_learner, ens_learner, results[i,0] = surrogate_model_training(system, training_strategy, n_train_random, n_initial, n_queries, temporal_pool_size, n_instances)\n",
    "    system.AI_model.lol_model = lol_learner\n",
    "    system.AI_model.ens_model = ens_learner\n",
    "\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "    # print('MLMC results: ', results[i,:])\n",
    "\n",
    "# results_random_11 = results.copy()\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec3750",
   "metadata": {},
   "source": [
    "# Exact model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run MLMC\n",
    "n_run_MLMC = 10\n",
    "\n",
    "# initialize parameters for run\n",
    "samples = 25\n",
    "n_run = 40\n",
    "time_seconds = 50\n",
    "\n",
    "# Estimator: MC , Architecture: Exact\n",
    "ml_hierarchy = ['OptimalNStore']\n",
    "\n",
    "results = np.zeros((n_run_MLMC, 8))\n",
    "for i in range(n_run_MLMC):\n",
    "    time_start = time.time()\n",
    "    mcc = run_MLMC(system, samples, n_run, time_seconds, ml_hierarchy, use_joblib=False, verbose=False)\n",
    "    time_end = time.time()\n",
    "    results[i,0] = time_end - time_start\n",
    "    results[i,1:] = generate_mcc_results(mcc)\n",
    "\n",
    "avg_results = np.mean(results, axis=0)\n",
    "print('Average results: ', avg_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLMC_AL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
